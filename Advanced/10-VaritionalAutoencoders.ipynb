{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOr3yeAQwnP+KEE747CplAK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3Om7iyCJh4L4"},"outputs":[],"source":["# Para realizar el Varitional Autoencoder es necesario modificar el Autoencoder\n","# en el Encoder y en la loss function\n","\n","# En un autoencoder, cada imagen es mapeada directamente a un punto en el latent space.\n","# En un Varitional Autoencoder, cada imagen es mapeada hacia una distribución\n","# normal multivariable al rededor del punto del latent space.\n","\n","# El Encoder solo necesita mapear acada entrada a un vector de media y a un vector de vacrianza\n","# El Varitional Autoencoder asume que no hay correlación entre las dimensiones en\n","# el espacio latente.\n","\n","# El encoder tomará cada imagen de entrada y la codificara en dos vectores que\n","# juntos definen a distribución normal multivariable en latent space.\n","# 1. z_mean     ---> El punto medio de la distribución.\n","# 2. z_log_var  ---> El logaritmo de la varianza de cada dimensión\n","\n","# En el Autoencoder, que una imagen en el punto (2,2) sea bien decodificada, no\n","# quiere decir que el punto (2.1,2.1) muestre algo similar.\n","# Al realizar una distribución normal, nos aseguramos que los puntos vecinos\n","# produzcan imágenes similares cuando son decodificadas."]},{"cell_type":"code","source":["import tensorflow as tf\n","import tensorflow.keras.backend as K\n","from tensorflow.keras import layers, models,datasets,callbacks,losses,optimizers,metrics\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from scipy.stats import norm"],"metadata":{"id":"w1iPXc1hqu3x","executionInfo":{"status":"ok","timestamp":1692974147949,"user_tz":360,"elapsed":3,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["# Cargar los datos\n","(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()\n","\n","# Preprocess the data\n","\n","def preprocess(imgs):\n","  # Normalizar y reajustar las imágenes\n","  igs= imgs.astype(\"float32\")/255.0\n","  imgs = np.pad(imgs, ((0,0),(2,2),(2,2)), constant_values=0.0)\n","  imgs = np.expand_dims(imgs, -1)\n","  return imgs\n","\n","x_train = preprocess(x_train)\n","x_test = preprocess(x_test)\n","\n","display(x_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"POzDt04prAsM","executionInfo":{"status":"ok","timestamp":1692974150296,"user_tz":360,"elapsed":323,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"44831210-42ba-4557-9f32-b4bd458298ac"},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["array([[[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]],\n","\n","\n","       [[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]],\n","\n","\n","       [[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]],\n","\n","\n","       ...,\n","\n","\n","       [[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]],\n","\n","\n","       [[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]],\n","\n","\n","       [[[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        ...,\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]],\n","\n","        [[0],\n","         [0],\n","         [0],\n","         ...,\n","         [0],\n","         [0],\n","         [0]]]], dtype=uint8)"]},"metadata":{}}]},{"cell_type":"code","source":["# 1. Neceistamos crear un nuevo tipo de Sampling layer (Muestreo) que nos permitirá\n","# muestrear desde la distribución definida por el z_mean y el z_log_var\n","\n","# Creamos una nueva capa \"Subclassing the Layer Class\"\n","class Sampling(layers.Layer):\n","  def call(self, inputs):\n","    z_mean, z_log_var = inputs\n","    batch = tf.shape(z_mean)[0]\n","    dim = tf.shape(z_mean)[1]\n","    epsilon = K.random_normal(shape=(batch, dim))\n","    return z_mean + tf.exp(0.5*z_log_var)*epsilon # Usamos el truco de la\n","    # subparametrización para construir una muestra desde la distribución\n","    # normal parametrizada con z_mean y z_log_var\n","\n","# --- Subclassig the layer class ---\n","# Se pueden crear nuevas capas de Keras subclassing the abstract Layer class y\n","# definiendo el método Call, que describe cómo un tensor es transformado por la capa\n","\n","# Por ejemplo, en un AutoEncoder varicional, podemos crear un capara de muestreo\n","# que puede manejar el muestreo de z desde una distribución normal con\n","# parámetros definidos por z_mean y z_log_var.\n","\n","# --- The Reparameterization Trick ---\n","# En lugar de muestrear directamente desde una distribución normal con parámetros\n","# z_mean y z_log_var, podemos tomar muestras epsilon desde una Normal Standar y\n","# entonces, ajustar manualmente la muestra para obtener la media y varainza correctas\n"],"metadata":{"id":"Xn3UvIqcnGri","executionInfo":{"status":"ok","timestamp":1692974153252,"user_tz":360,"elapsed":2,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["# Para completar el encoder, incluímos la nueva Sampling Layer\n","encoder_input = layers.Input(\n","    shape=(32,32,1), name=\"encoder_input\")\n","x = layers.Conv2D(32,(3,3),strides=2,activation=\"relu\",padding='same')(encoder_input)\n","x = layers.Conv2D(64,(3,3),strides=2,activation='relu',padding='same')(x)\n","x = layers.Conv2D(128,(3,3),strides=2,activation='relu',padding='same')(x)\n","shape_before_flattening=K.int_shape(x)[1:]\n","\n","x = layers.Flatten()(x)\n","# En lugar de conectar directamente la capa Flatten a el espacio latente 2D,\n","# la conectamos a las capas z_mean y z_log_var\n","z_mean = layers.Dense(2,name='z_mean')(x)\n","z_log_var = layers.Dense(2,name='z_log_var')(x)\n","# La capa Smapling muestrea un un punto z en el espacio latente desde la distribución\n","# normal definida por los parámetros z_mean y z_log_var\n","z = Sampling()([z_mean,z_log_var])\n","\n","# El modelo de Kera que define el encoder: Un modelo que toma una imagen de entrada\n","# y las salidas z_mean, z_log_var, y los puntos muestreados de la distribución normmal\n","# definida con esos parámetros\n","encoder = models.Model(encoder_input, [z_mean, z_log_var,z], name='encoder')\n","\n","encoder.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z0jzO_eVquF_","executionInfo":{"status":"ok","timestamp":1692974154300,"user_tz":360,"elapsed":29,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"baacea25-cf1d-4955-b8db-8d7f88376f2b"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"encoder\"\n","__________________________________________________________________________________________________\n"," Layer (type)                   Output Shape         Param #     Connected to                     \n","==================================================================================================\n"," encoder_input (InputLayer)     [(None, 32, 32, 1)]  0           []                               \n","                                                                                                  \n"," conv2d_3 (Conv2D)              (None, 16, 16, 32)   320         ['encoder_input[0][0]']          \n","                                                                                                  \n"," conv2d_4 (Conv2D)              (None, 8, 8, 64)     18496       ['conv2d_3[0][0]']               \n","                                                                                                  \n"," conv2d_5 (Conv2D)              (None, 4, 4, 128)    73856       ['conv2d_4[0][0]']               \n","                                                                                                  \n"," flatten_1 (Flatten)            (None, 2048)         0           ['conv2d_5[0][0]']               \n","                                                                                                  \n"," z_mean (Dense)                 (None, 2)            4098        ['flatten_1[0][0]']              \n","                                                                                                  \n"," z_log_var (Dense)              (None, 2)            4098        ['flatten_1[0][0]']              \n","                                                                                                  \n"," sampling_1 (Sampling)          (None, 2)            0           ['z_mean[0][0]',                 \n","                                                                  'z_log_var[0][0]']              \n","                                                                                                  \n","==================================================================================================\n","Total params: 100,868\n","Trainable params: 100,868\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"code","source":["# DECODER\n","decoder_input = layers.Input(shape=(2,),name=\"decoder_input\")\n","x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n","x = layers.Reshape(shape_before_flattening)(x)\n","x = layers.Conv2DTranspose(128,(3,3),strides=2,activation=\"relu\",padding=\"same\")(x)\n","x = layers.Conv2DTranspose(64,(3,3),strides=2,activation=\"relu\",padding=\"same\")(x)\n","x = layers.Conv2DTranspose(32,(3,3),strides=2,activation=\"relu\",padding=\"same\")(x)\n","decoder_output=layers.Conv2D(1,(3,3),strides=1,activation=\"sigmoid\",padding=\"same\",\n","                             name=\"decoder_output\")(x)\n","decoder=models.Model(decoder_input, decoder_output)\n","decoder.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sMyDKYjEAr67","executionInfo":{"status":"ok","timestamp":1692974156806,"user_tz":360,"elapsed":54,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"b0b30f3d-ecde-4818-8eba-31816544c14c"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," decoder_input (InputLayer)  [(None, 2)]               0         \n","                                                                 \n"," dense_4 (Dense)             (None, 2048)              6144      \n","                                                                 \n"," reshape_4 (Reshape)         (None, 4, 4, 128)         0         \n","                                                                 \n"," conv2d_transpose_10 (Conv2D  (None, 8, 8, 128)        147584    \n"," Transpose)                                                      \n","                                                                 \n"," conv2d_transpose_11 (Conv2D  (None, 16, 16, 64)       73792     \n"," Transpose)                                                      \n","                                                                 \n"," conv2d_transpose_12 (Conv2D  (None, 32, 32, 32)       18464     \n"," Transpose)                                                      \n","                                                                 \n"," decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n","                                                                 \n","=================================================================\n","Total params: 246,273\n","Trainable params: 246,273\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# La función de Pérdida\n","\n","# Nuestra función de pérdida requiere un componente extra:\n","# the Kullback-Leibler (KL) divergence term\n","\n","# KL divergence es una manera de medir qué tanto una distribución de probabilidad\n","# difiere de otra. En un VAE, queremos medir qué tanto nuestra distribución normal\n","# con parámetros z_mean y z_log_var difiere de una distribución normal estándar.\n","# En este casi, se puede mostrar de esta forma\n","# kl_loss = -0.5 * sum(1+z_log_var - z_mean^2 - exp(z_log_var))\n","# En resumen, la divergencia KL penaliza a la red por codificar observaciones a\n","# z_mean y z_log_var que difieren significativamente de los parámetros de la\n","# distribución estándar normal ---> z_mean=0 y z_log_var=0\n"],"metadata":{"id":"CB0bZN1qnGuX","executionInfo":{"status":"ok","timestamp":1692974157164,"user_tz":360,"elapsed":2,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["class VAE(models.Model):\n","  def __init__(self,encoder,decoder, **kwargs):\n","    super(VAE,self).__init__(**kwargs)\n","    self.encoder = encoder\n","    self.decoder = decoder\n","    self.total_loss_tracker = metrics.Mean(name=\"total_loss\")\n","    self.reconstruction_loss_tracker = metrics.Mean(\n","        name=\"reconstruction_loss\"\n","    )\n","    self.kl_loss_tracker = metrics.Mean(name=\"kl_loss\")\n","\n","  @property\n","  def metrics(self):\n","    return[self.total_loss_tracker,\n","           self.reconstruction_loss_tracker,\n","           self.kl_loss_tracker]\n","\n","  # Esta función describe lo que nos gustaría que devolviese lo que llamamos\n","  # VAE en una imagen de entrada en particular\n","  def call(self,inputs):\n","    z_mean,z_log_var,z=encoder(inputs)\n","    reconstruction=decoder(z)\n","    return z_mean, z_log_var, reconstruction\n","\n","  # Esta función describe un paso de entrenamiento del VAE, incluyenndo el\n","  # cálculo de la loss function\n","  def train_step(self,data):\n","    with tf.GradientTape() as tape:\n","      z_mean, z_log_var, reconstruction = self(data)\n","      reconstruction_loss = tf.reduce_mean(\n","          500*losses.binary_crossentropy(data,reconstruction,axis=(1,2,3))\n","      )# Se utiliza un valor beta de 500 en la loss reconstruction\n","      kl_loss=tf.reduce_mean(\n","          tf.reduce_sum(-0.5*(1+z_log_var-tf.square(z_mean)-tf.exp(z_log_var)),\n","                        axis=1))\n","      # La pérdida total es la suma de la pérdida reconstrucción de pérdida y\n","      # la pérdida de divergencia KL\n","      total_loss = reconstruction_loss + kl_loss\n","\n","    grads = tape.gradient(total_loss, self.trainable_weights)\n","    self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n","\n","    self.total_loss_tracker.update_state(total_loss)\n","    self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n","    self.kl_loss_tracker.update_state(kl_loss)\n","\n","    return {m.name:m.result() for m in self.metrics}\n","    # Gradient Tape es un mecanismo que permite el cómputo de gradiente de operación,\n","    # ejecutados durante el paso hacia delante del modelo.\n","\n","def test_step(self,data):\n","  \"\"\"Step run during validation.\"\"\"\n","  if isinstance(data,tuple):\n","    data = data[0]\n","\n","  z_mean, z_log_var, reconstruction = self(data)\n","  reconstruction_loss = tf.reduce_mean(500*losses.binary_crossentropy(data,\n","                                                                      reconstruction,axis=(1,2,3)))\n","  kl_loss = tf.reduce_mean(tf.reduce_sum(-0.5*(1+z_log_var-tf.square(z_mean)-tf.exp(z_log_var)),\n","                                         axis=1))\n","  total_loss = reconstruction_loss + kl_loss\n","\n","  return{\n","      \"loss\":total_loss,\n","      \"reconstruction_loss\": reconstruction_loss,\n","      \"kl_loss\": kl_loss\n","  }\n","\n"],"metadata":{"id":"j_FME3MwnGxd","executionInfo":{"status":"ok","timestamp":1692974159555,"user_tz":360,"elapsed":3,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Compilar el VAE\n","vae = VAE(encoder, decoder)\n","optimizer = optimizers.Adam(learning_rate=0.0005)\n","vae.compile(optimizer=optimizer)"],"metadata":{"id":"bLvi_H5F7Xcs","executionInfo":{"status":"ok","timestamp":1692974161463,"user_tz":360,"elapsed":3,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["# Crear un checkpoint de guardado del modelo\n","model_checkpoint_callback = callbacks.ModelCheckpoint(\n","    filepath=\"./checkpoint\",\n","    save_weights_only=False,\n","    save_freq=\"epoch\",\n","    monitor=\"loss\",\n","    mode=\"min\",\n","    save_best_only=True,\n","    verbose=0\n",")\n","tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")"],"metadata":{"id":"Fy6XZRWTDwCg","executionInfo":{"status":"ok","timestamp":1692974163015,"user_tz":360,"elapsed":3,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["# Entrenar el VAE\n","vae.fit(x_train,\n","        epochs=10,\n","        batch_size=100,\n","        shuffle=True,\n","        validation_data=(x_test,x_test),\n","        callbacks=[model_checkpoint_callback, tensorboard_callback])"],"metadata":{"id":"O0288Jkz7XfT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692974237502,"user_tz":360,"elapsed":72851,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"4e96b21b-93ee-4f96-9b3b-b9bb7ac939d8"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","598/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 21s 10ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 2/10\n","599/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 10ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 3/10\n","599/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 7s 11ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 4/10\n","598/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 10ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 5/10\n","600/600 [==============================] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 6/10\n","600/600 [==============================] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 7/10\n","595/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 8/10\n","595/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 9/10\n","595/600 [============================>.] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 6s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n","Epoch 10/10\n","600/600 [==============================] - ETA: 0s - total_loss: nan - reconstruction_loss: nan - kl_loss: nan"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r600/600 [==============================] - 5s 9ms/step - total_loss: nan - reconstruction_loss: nan - kl_loss: nan - val_total_loss: 0.0000e+00 - val_reconstruction_loss: 0.0000e+00 - val_kl_loss: 0.0000e+00\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7acb56f1b130>"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["# Guardar el modelo final\n","vae.save(\"./models/vae\")\n","encoder.save(\"./models/encoder\")\n","decoder.save(\"./models/decoder\")"],"metadata":{"id":"QMdpVLGGnGzv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692974243568,"user_tz":360,"elapsed":6068,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"b6e76caf-2589-4338-ca2b-33dd335e3ea9"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 7). These functions will not be directly callable after loading.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n","WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"]}]},{"cell_type":"code","source":["# Reconstruir usando el VAE\n","\n","# Seleccionar un subset del test set\n","n_to_predict = 5000\n","example_images = x_test[:n_to_predict]\n","example_labels = y_test[:n_to_predict]"],"metadata":{"id":"s5d-kLShEOfX","executionInfo":{"status":"ok","timestamp":1692974243569,"user_tz":360,"elapsed":9,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Crear predicciones del autoencoder y mostrarlas\n","\n","\n","z_mean, z_log_var, reconstructions = vae.predict(example_images)\n","print(\"Example real clothing items\")\n","display(example_images)\n","print(\"Reconstructions\")\n","display(reconstructions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"bFe86S67EOhn","executionInfo":{"status":"ok","timestamp":1692974277631,"user_tz":360,"elapsed":4614,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"1e72fd4e-9fc1-4ddc-de9b-23c330e70b81"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["157/157 [==============================] - 3s 8ms/step\n","Example real clothing items\n"]},{"output_type":"display_data","data":{"text/plain":["array([[[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]],\n","\n","\n","       [[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]],\n","\n","\n","       [[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]],\n","\n","\n","       ...,\n","\n","\n","       [[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [10],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]],\n","\n","\n","       [[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]],\n","\n","\n","       [[[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        ...,\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]],\n","\n","        [[ 0],\n","         [ 0],\n","         [ 0],\n","         ...,\n","         [ 0],\n","         [ 0],\n","         [ 0]]]], dtype=uint8)"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Reconstructions\n"]},{"output_type":"display_data","data":{"text/plain":["array([[[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]],\n","\n","\n","       [[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]],\n","\n","\n","       [[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]],\n","\n","\n","       ...,\n","\n","\n","       [[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]],\n","\n","\n","       [[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]],\n","\n","\n","       [[[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        ...,\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]],\n","\n","        [[nan],\n","         [nan],\n","         [nan],\n","         ...,\n","         [nan],\n","         [nan],\n","         [nan]]]], dtype=float32)"]},"metadata":{}}]},{"cell_type":"code","source":[],"metadata":{"id":"6XckZnsREOkH"},"execution_count":null,"outputs":[]}]}