{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyOyHszdNIoCZNQFEkftbdeB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3f6e3La-mQoN","executionInfo":{"status":"ok","timestamp":1692216692155,"user_tz":360,"elapsed":1180,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"21a03cae-e2c2-4ba0-e05f-7dfaa69d7f73"},"outputs":[{"output_type":"stream","name":"stdout","text":["['me' 'gusta' 'el' 'deep' 'learning']\n","[4 2 1 0 3]\n","[[0. 0. 0. 0. 1.]\n"," [0. 0. 1. 0. 0.]\n"," [0. 1. 0. 0. 0.]\n"," [1. 0. 0. 0. 0.]\n"," [0. 0. 0. 1. 0.]]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n","  warnings.warn(\n"]}],"source":["# Téncnica One-hot encoding\n","from numpy import array\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","\n","doc = \"Me gusta el Deep Learning\"\n","doc = doc.lower()\n","doc = doc.split()\n","values = array(doc)\n","print(values)\n","\n","# 1. Convertir las palabras en tokens y obtener su valor numérico\n","# de la posición utilizando LabelEncoder()\n","label_encoder = LabelEncoder()\n","integer_encoded = label_encoder.fit_transform(values)\n","print(integer_encoded)\n","\n","# 2. Obtener la codificación one-hot de la palabra utilizando OneHotEncoder()\n","\n","onehot_encoder = OneHotEncoder(sparse=False)\n","integer_encoded = integer_encoded.reshape(len(integer_encoded),1)\n","onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n","print(onehot_encoded)"]},{"cell_type":"code","source":["# Embedding layer de Keras\n","layers.Embedding(input_dim=vocab_size,\n","                 output_dim=embedding_dim)"],"metadata":{"id":"5qP0q9Ka_wnM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# EJEMPLO: Character-Level Language Model por Andrej Karpathy\n","# Consiste en darle a la RNN una palabra, entonces se le pide que modele\n","# la distribución de probabilidad del siguiente carácter que le correspondería\n","# a la secuencia de caracteres anterores.\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!ls\n","path_to_fileDL = '/content/drive/MyDrive/Antología-literaria-1.txt'\n","text = open(path_to_fileDL, 'rb').read().decode(encoding='utf-8')\n","print('Longitud del texto: {} carácteres'.format(len(text)))\n","vocab = sorted(set(text))\n","print('El texto está compuesto de esto {} carácteres:'.format(len(vocab)))\n","print(vocab)\n","#Como estamos tratando el caso de estudio a nivel de carácter, podríamos considerar\n","# que aquí el corpus son los caracteres y, por tanto, sería un corpus muy pequeño.\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TmavrEzd_wpq","executionInfo":{"status":"ok","timestamp":1692379406817,"user_tz":360,"elapsed":1321,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"214418ce-d86f-4f74-915c-be040c4b9421"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","drive  sample_data  training_checkpoints\n","Longitud del texto: 249659 carácteres\n","El texto está compuesto de esto 111 carácteres:\n","['\\t', '\\n', '\\x0c', ' ', '!', '(', ')', '*', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '<', '=', '>', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '©', '«', '\\xad', '´', 'º', '»', '¿', 'Á', 'É', 'Í', 'Ñ', 'Ó', 'Ú', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '–', '—', '’', '“', '”', '•', '…']\n"]}]},{"cell_type":"code","source":["# Las redes neuronales solo procesan valores numéricos, no letras\n","import tensorflow as tf\n","from tensorflow import keras\n","import numpy as np\n","from numpy import array\n","\n","char2idx = {u:i for i, u in enumerate(vocab)}\n","idx2char = np.array(vocab)\n","\n","# Ahora tenemos un token con la representación de entero (integer) para\n","# cada carácter, como podemos ver ejecutando el siguiente código\n","for char,_ in zip(char2idx, range(len(vocab))):\n","  print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rJtxlVCG_wtM","executionInfo":{"status":"ok","timestamp":1692379409983,"user_tz":360,"elapsed":162,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"ec0b9299-3f0a-42f1-a2ca-c2beeb375f44"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":[" '\\t':   0,\n"," '\\n':   1,\n"," '\\x0c':   2,\n"," ' ' :   3,\n"," '!' :   4,\n"," '(' :   5,\n"," ')' :   6,\n"," '*' :   7,\n"," ',' :   8,\n"," '-' :   9,\n"," '.' :  10,\n"," '/' :  11,\n"," '0' :  12,\n"," '1' :  13,\n"," '2' :  14,\n"," '3' :  15,\n"," '4' :  16,\n"," '5' :  17,\n"," '6' :  18,\n"," '7' :  19,\n"," '8' :  20,\n"," '9' :  21,\n"," ':' :  22,\n"," ';' :  23,\n"," '<' :  24,\n"," '=' :  25,\n"," '>' :  26,\n"," '?' :  27,\n"," 'A' :  28,\n"," 'B' :  29,\n"," 'C' :  30,\n"," 'D' :  31,\n"," 'E' :  32,\n"," 'F' :  33,\n"," 'G' :  34,\n"," 'H' :  35,\n"," 'I' :  36,\n"," 'J' :  37,\n"," 'K' :  38,\n"," 'L' :  39,\n"," 'M' :  40,\n"," 'N' :  41,\n"," 'O' :  42,\n"," 'P' :  43,\n"," 'Q' :  44,\n"," 'R' :  45,\n"," 'S' :  46,\n"," 'T' :  47,\n"," 'U' :  48,\n"," 'V' :  49,\n"," 'W' :  50,\n"," 'X' :  51,\n"," 'Y' :  52,\n"," 'Z' :  53,\n"," '[' :  54,\n"," ']' :  55,\n"," '_' :  56,\n"," 'a' :  57,\n"," 'b' :  58,\n"," 'c' :  59,\n"," 'd' :  60,\n"," 'e' :  61,\n"," 'f' :  62,\n"," 'g' :  63,\n"," 'h' :  64,\n"," 'i' :  65,\n"," 'j' :  66,\n"," 'k' :  67,\n"," 'l' :  68,\n"," 'm' :  69,\n"," 'n' :  70,\n"," 'o' :  71,\n"," 'p' :  72,\n"," 'q' :  73,\n"," 'r' :  74,\n"," 's' :  75,\n"," 't' :  76,\n"," 'u' :  77,\n"," 'v' :  78,\n"," 'w' :  79,\n"," 'x' :  80,\n"," 'y' :  81,\n"," 'z' :  82,\n"," '¡' :  83,\n"," '©' :  84,\n"," '«' :  85,\n"," '\\xad':  86,\n"," '´' :  87,\n"," 'º' :  88,\n"," '»' :  89,\n"," '¿' :  90,\n"," 'Á' :  91,\n"," 'É' :  92,\n"," 'Í' :  93,\n"," 'Ñ' :  94,\n"," 'Ó' :  95,\n"," 'Ú' :  96,\n"," 'á' :  97,\n"," 'é' :  98,\n"," 'í' :  99,\n"," 'ñ' : 100,\n"," 'ó' : 101,\n"," 'ú' : 102,\n"," 'ü' : 103,\n"," '–' : 104,\n"," '—' : 105,\n"," '’' : 106,\n"," '“' : 107,\n"," '”' : 108,\n"," '•' : 109,\n"," '…' : 110,\n"]}]},{"cell_type":"code","source":["# Con esta función, inversa a la anterior, podemos pasar el texto (todo el libro) a enteros\n","text_as_int = np.array([char2idx[c] for c in text])\n","\n","# Lo comprobaremos mostrando los 50 primeros caracteres del teexto\n","print('texto: {}'.format(repr(text[:50])))\n","print('{}'.format(repr(text_as_int[:50])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wNpeoTVyw99E","executionInfo":{"status":"ok","timestamp":1692379413440,"user_tz":360,"elapsed":106,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"6690f465-d564-4deb-969e-7ad705b7c027"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["texto: 'SECUNDARIA\\n\\nEscudo Nacional\\n\\n1\\n\\nANTOLOGÍA LITERARI'\n","array([46, 32, 30, 48, 41, 31, 28, 45, 36, 28,  1,  1, 32, 75, 59, 77, 60,\n","       71,  3, 41, 57, 59, 65, 71, 70, 57, 68,  1,  1, 13,  1,  1, 28, 41,\n","       47, 42, 39, 42, 34, 93, 28,  3, 39, 36, 47, 32, 45, 28, 45, 36])\n"]}]},{"cell_type":"code","source":["# PREPARACIÓN DE LOS DATOS PARA SER USADOS POR LA RNN\n","\n","# En nuestro ejemplo definios la variable se_lenght = 100\n","# Significa que dividiremos secuencias de seq_lenght+1 de caracteres\n","# y las iremos desplazando un caracter a la derecha\n","\n","# La función tf.data.Dataset from_tensor_slices, crea un conjunto de datos\n","# con el contenido del tensor text_as_int que contiene el texto, al que podremos\n","# aplicar el método batch() para divir este conjunnto de datos en secuencias de seq_lenght+1\n","char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n","seq_lenght = 100\n","sequences = char_dataset.batch(seq_lenght+1,drop_remainder=True)\n","\n","# Comprobamos que sequences contiene el texto dividido en paquetes de 101 caracteres\n","for item in sequences.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FoG0iMNww-Fz","executionInfo":{"status":"ok","timestamp":1692379414617,"user_tz":360,"elapsed":116,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"9064512e-dc07-46c3-c7e1-c216356c90a3"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["'SECUNDARIA\\n\\nEscudo Nacional\\n\\n1\\n\\nANTOLOGÍA LITERARIA\\n\\nSECUNDARIA\\n\\nISBN 978-612-01-0310-4\\n\\nBandera Naci'\n","'onal\\n\\nAntología\\nliteraria\\n\\n1\\n\\n\\x0cMINISTERIO DE EDUCACIÓN\\nDirección de Educación Secundaria\\n\\nAntología\\nl'\n","'iteraria\\n1\\n\\n1\\n\\nAntologías 1ro_26JUN.indd 1\\n\\n22/08/18 9:11\\n\\n\\x0cZ_Antologías Literaria 1ro - Pg02 Credito'\n","'.pdf\\n\\n1\\n\\n14/12/18\\n\\n10:54\\n\\nTítulo: Antología literaria 3\\nTítulo: Antología literaria 1\\nMinisterio de E'\n","'ducación\\nMinisterio\\nde Educación\\nCalle\\nDel Comercio\\nN.º 193, San Borja\\nCalle Del Comercio N.º 193, Sa'\n","'n Borja\\nLima 41, Perú\\nLima 41, Perú\\nTeléfono: 615-5800\\nTeléfono: 615-5800\\nwww.minedu.gob.pe\\nwww.mined'\n","'u.gob.pe\\nPrimera edición: 2015\\nPrimera edición: 2015\\nSegunda edición: junio de 2017\\nCuarta reimpresió'\n","'n: noviembre de 2018\\nTiraje: 457 169 ejemplares\\nTiraje: 550 824 ejemplares\\nCoordinadora\\nKaren\\nCoral R'\n","'odríguez\\nCoordinadora\\nKaren Coral Rodríguez\\nAntologadores\\nMarco\\nBassino Pinasco\\nAntologadores\\nMarcel\\n'\n","'Velázquez\\nCastro\\nMarco Bassino\\nPinasco\\nMarcel Velázquez Castro\\nEditor\\nAlfredo\\nEditor Acevedo Nestárez'\n"]}]},{"cell_type":"code","source":["# De esta secuencia se obtiene el conjunto de datos de entrenamiento\n","# Se crea la función que divide los datos de entrada (0 al 99) de los de\n","# salida (1 al 100)\n","\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text = chunk[1:]\n","  return input_text, target_text\n","dataset = sequences.map(split_input_target)\n","\n","# Se puede comprobar así\n","for input_example, target_example in dataset.take(1):\n","  print('Input data:',\n","        repr(''.join(idx2char[input_example.numpy()])))\n","  print('Target data:',\n","        repr(''.join(idx2char[target_example.numpy()])))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKpiMHnWw-KK","executionInfo":{"status":"ok","timestamp":1692379415718,"user_tz":360,"elapsed":130,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"e4b1d978-7e5a-4e6a-ede6-7e9f1476d487"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Input data: 'SECUNDARIA\\n\\nEscudo Nacional\\n\\n1\\n\\nANTOLOGÍA LITERARIA\\n\\nSECUNDARIA\\n\\nISBN 978-612-01-0310-4\\n\\nBandera Nac'\n","Target data: 'ECUNDARIA\\n\\nEscudo Nacional\\n\\n1\\n\\nANTOLOGÍA LITERARIA\\n\\nSECUNDARIA\\n\\nISBN 978-612-01-0310-4\\n\\nBandera Naci'\n"]}]},{"cell_type":"code","source":["# En este punto, disponemos de los datos de entrenamiento en el tensor dataset\n","# en forma de parejas de secuencias de 100 integers de 64 bits que representan\n","# un carácter del vocabulario\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p68yoC3sw-Mr","executionInfo":{"status":"ok","timestamp":1692379417573,"user_tz":360,"elapsed":122,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"18f0e7c5-210a-4f5c-ec98-8dd67feb36e5"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["<_MapDataset element_spec=(TensorSpec(shape=(100,), dtype=tf.int64, name=None), TensorSpec(shape=(100,), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"code","source":["# Los datos ya están preprocesados en el formato que se requiere para ser usados\n","# en el entreno de la red, pero recordemos que estos deben de ser agruapdos en\n","# batches antes de pasarlos al modelo.\n","# Se utilizará la función tf.data, que también eprmite barajar las secuencias previamente\n","\n","BATCH_SIZE = 64\n","BUFFER_SIZE = 10000\n","\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print(dataset)\n","\n","# Es así que tenemos batches compuestos de 64 parejas de secuencias de 100 integers\n","# de 64 bits que representan el carácter correspondiente del vocabulario\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zsp5byPl0R8v","executionInfo":{"status":"ok","timestamp":1692379418937,"user_tz":360,"elapsed":138,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"1d7e83b6-328c-4330-8036-7929c4cabde2"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["<_BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"code","source":["# CONSTRUCCIÓN DEL MODELO RNN\n","# Usaremos una versión mínima de RNN para facilitar la explicación, que contega\n","# solo una capa LSTM.\n","# En concreto, definimos uan red de solo 3 capas\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Embedding, LSTM, Dense\n","\n","def build_model(vocab_size, embedding_dim,rnn_units,batch_size):\n","  model=Sequential()\n","  model.add(Embedding(input_dim=vocab_size,\n","                      output_dim=embedding_dim,\n","                      batch_input_shape=[batch_size,None]))\n","  model.add(LSTM(rnn_units,\n","                 return_sequences=True,\n","                 stateful=True,\n","                 recurrent_initializer='glorot_uniform'))\n","  model.add(Dense(vocab_size))\n","  return model\n","\n","vocab_size = len(vocab)\n","embedding_dim = 256\n","rnn_units = 1024\n","\n","model = build_model(\n","   vocab_size = vocab_size,\n","   embedding_dim = embedding_dim,\n","   rnn_units=rnn_units,\n","   batch_size=BATCH_SIZE\n",")\n","\n","# La primera capa es de tipo word embedding, que mapea cada carácter de entrada\n","# en un vector ambedding. Esta capa permite especificar varios argumentos:\n","# 1. Tamaño del vocabulario, que indica cuántos vectores embedding tendrá la capa\n","# 2. Dimensiones de estos vectores embedding, que son 256\n","# 3. Tamaño del batch, que es de 64\n","\n","# La segunda capa es de tipo LSTM. rnn_units indica el número de neuronas recurrentes\n","# Con return_sequence se indica si queremos predecir el carácter siguiente a\n","# todos los caracteres de entrada, no solo al último carácter.\n","# El argumento stateful indica, el uso de las capacidades de memoria de la red\n","# entre batches. Si es False: cada nuevo batch se inicializan las memory cell.\n","# Si es False, para chada batch se mantendrán las actualizaciones hechas durante\n","# la ejecuación del batch anterior\n","# Recurrente_kernel inidca cómo deben inicializar los pesos de las matrices internas\n","# de la red. En este caso usamos la distribución uniforme glorot_uniform, habitual\n","# en estos casos.\n","\n","# La última capa es de tipo Dense. El argumento units nos dice cuántas neuronas\n","# tendrá la capa y que nos marcará la dimensión de la salida. En este caso será\n","# igual al tamaño de nuestro vocabulario (vocab_size)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LGQNMdgJ0SE8","executionInfo":{"status":"ok","timestamp":1692379422352,"user_tz":360,"elapsed":376,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"a7f7bd67-f536-477d-e35b-fe78a24d6776"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (64, None, 256)           28416     \n","                                                                 \n"," lstm_2 (LSTM)               (64, None, 1024)          5246976   \n","                                                                 \n"," dense_2 (Dense)             (64, None, 111)           113775    \n","                                                                 \n","=================================================================\n","Total params: 5,389,167\n","Trainable params: 5,389,167\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# Inspeccionamos las dimensiones de los tensores para poder comprender más\n","# a fondo el modelo.\n","for input_example_batch, target_example_batch in dataset.take(1):\n","  print(\"Input:\", input_example_batch.shape, \"#(batch_size, sequence_lenght)\")\n","  print(\"Target:\",target_example_batch.shape, \"#(batch_size, sequence_lenght)\")\n","\n","# Vemos que en esta red la secuencia de entrada son batches de 100 caracteres, pero\n","# el modelo una vez entrenado puede ser ejecutado con cualquier tamaño de cadena\n","# de entrada.\n","# Como salida, el modelo nos devuelve un tensor con una dimensión adicional con\n","# la verosimilitud para cada carácter del vocabulario:\n","\n","for input_example_batch, target_example_batch in dataset.take(1):\n","  example_batch_predictions = model(input_example_batch)\n","  print(\"Prediction: \", example_batch_predictions.shape,\n","        \"#(batch_size, sequence_lenght, vocab_size)\")\n","\n","# La capa Densa de esta red no tiene una función de activación softmax, es por eso\n","# que retorna el vector con un indicador de \"evidencia\" para cada carácter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3bKhxUjlBIJ","executionInfo":{"status":"ok","timestamp":1692379426799,"user_tz":360,"elapsed":1127,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"d153cb4f-06db-46ae-817f-ae0d297a5aea"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: (64, 100) #(batch_size, sequence_lenght)\n","Target: (64, 100) #(batch_size, sequence_lenght)\n","Prediction:  (64, 100, 111) #(batch_size, sequence_lenght, vocab_size)\n"]}]},{"cell_type":"code","source":["# El siguiente paso es elegir uno de los caracteres. No se elige el más probable,\n","# porque puede entrar en un bucle. Se obtiene una muestra de la distribución de salida\n","\n","# Se prueba para el primer ejjemplo en el batch\n","sampled_indices = tf.random.categorical(\n","    example_batch_predictions[0],\n","    num_samples=1)\n","sampled_indices_characters = tf.squeeze(\n","    sampled_indices,axis=-1).numpy()\n","print(sampled_indices_characters)\n","\n","# Con tf.random.categorical se obtiene una muestra de una distibución categórica\n","# y con squeeze se eliminan las dimensiones del tensor de tamaño 1. Así, en cada\n","# instante de tiempo se obtiene una predicción del índice del siguiente carácter.\n"],"metadata":{"id":"pEQl9LxhlBKq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692379427408,"user_tz":360,"elapsed":105,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"a12d492e-ba1f-4db9-8fd1-21a05b1585bb"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 86  38  54   0  66  91  73  73   9  95  67  48  34  28  98  40  67  20\n","  48  84  81   2  93  40  72  62  17  41  48  12  56  94  87  37  90  36\n","  60  17  12  16  96  43  80  62   9  29  95  47  71 102  26  87  76  80\n","  57  84  59  62  24  15  39  46  67  93  59  64  28   3  65  41  30  86\n","  71  70  22  25  62  45  97  31  33  50  66  59  70  87  29  84  61  59\n"," 108  68  19  18   6 100  61  14   9  77]\n"]}]},{"cell_type":"code","source":["# ENTRENAMIENTO DEL MODELO RNN\n","# Para la función de pérdida usaremos al función estándar tf.leras.losses.sparse_categorcial_crossentropy,\n","# pues se trata de datos categóricos. Dado que el retorno se trata de valores de\n","# verosimilitud (no de probabilidades) se instanciará el argumento from_logits a True\n","\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(\n","      labels,logits,from_logits=True)\n","\n","# En cuanto al optimizador, se usará el Adam con argumentos por defecto\n","model.compile(optimizer='adam', loss=loss)"],"metadata":{"id":"ViqEoMZJ34u8","executionInfo":{"status":"ok","timestamp":1692379428841,"user_tz":360,"elapsed":104,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Se aprovecharán los Checkpoints, una técnica de tolerancia de fallos para\n","# procesos cuyo tiempo de ejecución es muy largo.\n","# La librería de Keras proporciona Checkpoints a través de la API Callbacks.\n","# Se debe especificar el directorio en el que se guardarán los Checkpoints y\n","# el nombre del fichero\n","\n","import os\n","checkpoint_dir = './training_checkpoints'\n","checkpoint_prefix=os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n","                                                       save_weights_only=True)"],"metadata":{"id":"S5hCgAvo34xq","executionInfo":{"status":"ok","timestamp":1692379430053,"user_tz":360,"elapsed":117,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["EPOCHS=50\n","history=model.fit(dataset,\n","                  epochs=EPOCHS,\n","                  callbacks=[checkpoint_callback])\n","\n","!ls training_checkpoints"],"metadata":{"id":"xYaasq7mlBN6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1692379634655,"user_tz":360,"elapsed":202674,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"fe404029-e182-4d03-c3a2-4a979fa69c79"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/50\n","38/38 [==============================] - 7s 113ms/step - loss: 3.3715\n","Epoch 2/50\n","38/38 [==============================] - 4s 81ms/step - loss: 2.8273\n","Epoch 3/50\n","38/38 [==============================] - 4s 78ms/step - loss: 2.4191\n","Epoch 4/50\n","38/38 [==============================] - 3s 73ms/step - loss: 2.2600\n","Epoch 5/50\n","38/38 [==============================] - 3s 70ms/step - loss: 2.1549\n","Epoch 6/50\n","38/38 [==============================] - 3s 79ms/step - loss: 2.0800\n","Epoch 7/50\n","38/38 [==============================] - 3s 77ms/step - loss: 2.0065\n","Epoch 8/50\n","38/38 [==============================] - 3s 71ms/step - loss: 1.9449\n","Epoch 9/50\n","38/38 [==============================] - 3s 80ms/step - loss: 1.8890\n","Epoch 10/50\n","38/38 [==============================] - 4s 89ms/step - loss: 1.8327\n","Epoch 11/50\n","38/38 [==============================] - 3s 73ms/step - loss: 1.7770\n","Epoch 12/50\n","38/38 [==============================] - 3s 77ms/step - loss: 1.7212\n","Epoch 13/50\n","38/38 [==============================] - 4s 72ms/step - loss: 1.6672\n","Epoch 14/50\n","38/38 [==============================] - 3s 73ms/step - loss: 1.6170\n","Epoch 15/50\n","38/38 [==============================] - 3s 73ms/step - loss: 1.5671\n","Epoch 16/50\n","38/38 [==============================] - 3s 75ms/step - loss: 1.5249\n","Epoch 17/50\n","38/38 [==============================] - 4s 74ms/step - loss: 1.4809\n","Epoch 18/50\n","38/38 [==============================] - 3s 79ms/step - loss: 1.4353\n","Epoch 19/50\n","38/38 [==============================] - 3s 75ms/step - loss: 1.3944\n","Epoch 20/50\n","38/38 [==============================] - 3s 76ms/step - loss: 1.3510\n","Epoch 21/50\n","38/38 [==============================] - 3s 75ms/step - loss: 1.3125\n","Epoch 22/50\n","38/38 [==============================] - 3s 76ms/step - loss: 1.2701\n","Epoch 23/50\n","38/38 [==============================] - 3s 77ms/step - loss: 1.2275\n","Epoch 24/50\n","38/38 [==============================] - 4s 76ms/step - loss: 1.1849\n","Epoch 25/50\n","38/38 [==============================] - 3s 77ms/step - loss: 1.1398\n","Epoch 26/50\n","38/38 [==============================] - 3s 78ms/step - loss: 1.0970\n","Epoch 27/50\n","38/38 [==============================] - 4s 77ms/step - loss: 1.0519\n","Epoch 28/50\n","38/38 [==============================] - 3s 79ms/step - loss: 1.0032\n","Epoch 29/50\n","38/38 [==============================] - 4s 77ms/step - loss: 0.9559\n","Epoch 30/50\n","38/38 [==============================] - 3s 80ms/step - loss: 0.9097\n","Epoch 31/50\n","38/38 [==============================] - 4s 79ms/step - loss: 0.8653\n","Epoch 32/50\n","38/38 [==============================] - 4s 77ms/step - loss: 0.8158\n","Epoch 33/50\n","38/38 [==============================] - 4s 80ms/step - loss: 0.7718\n","Epoch 34/50\n","38/38 [==============================] - 4s 78ms/step - loss: 0.7250\n","Epoch 35/50\n","38/38 [==============================] - 3s 79ms/step - loss: 0.6828\n","Epoch 36/50\n","38/38 [==============================] - 4s 82ms/step - loss: 0.6413\n","Epoch 37/50\n","38/38 [==============================] - 3s 79ms/step - loss: 0.6028\n","Epoch 38/50\n","38/38 [==============================] - 3s 79ms/step - loss: 0.5647\n","Epoch 39/50\n","38/38 [==============================] - 4s 82ms/step - loss: 0.5322\n","Epoch 40/50\n","38/38 [==============================] - 4s 80ms/step - loss: 0.5006\n","Epoch 41/50\n","38/38 [==============================] - 3s 80ms/step - loss: 0.4740\n","Epoch 42/50\n","38/38 [==============================] - 4s 82ms/step - loss: 0.4470\n","Epoch 43/50\n","38/38 [==============================] - 4s 81ms/step - loss: 0.4270\n","Epoch 44/50\n","38/38 [==============================] - 3s 78ms/step - loss: 0.4077\n","Epoch 45/50\n","38/38 [==============================] - 3s 79ms/step - loss: 0.3902\n","Epoch 46/50\n","38/38 [==============================] - 4s 81ms/step - loss: 0.3775\n","Epoch 47/50\n","38/38 [==============================] - 4s 79ms/step - loss: 0.3581\n","Epoch 48/50\n","38/38 [==============================] - 3s 79ms/step - loss: 0.3465\n","Epoch 49/50\n","38/38 [==============================] - 3s 81ms/step - loss: 0.3361\n","Epoch 50/50\n","38/38 [==============================] - 4s 82ms/step - loss: 0.3260\n","checkpoint\t\t     ckpt_33.data-00000-of-00001\n","ckpt_10.data-00000-of-00001  ckpt_33.index\n","ckpt_10.index\t\t     ckpt_34.data-00000-of-00001\n","ckpt_11.data-00000-of-00001  ckpt_34.index\n","ckpt_11.index\t\t     ckpt_35.data-00000-of-00001\n","ckpt_12.data-00000-of-00001  ckpt_35.index\n","ckpt_12.index\t\t     ckpt_36.data-00000-of-00001\n","ckpt_13.data-00000-of-00001  ckpt_36.index\n","ckpt_13.index\t\t     ckpt_37.data-00000-of-00001\n","ckpt_14.data-00000-of-00001  ckpt_37.index\n","ckpt_14.index\t\t     ckpt_38.data-00000-of-00001\n","ckpt_15.data-00000-of-00001  ckpt_38.index\n","ckpt_15.index\t\t     ckpt_39.data-00000-of-00001\n","ckpt_16.data-00000-of-00001  ckpt_39.index\n","ckpt_16.index\t\t     ckpt_3.data-00000-of-00001\n","ckpt_17.data-00000-of-00001  ckpt_3.index\n","ckpt_17.index\t\t     ckpt_40.data-00000-of-00001\n","ckpt_18.data-00000-of-00001  ckpt_40.index\n","ckpt_18.index\t\t     ckpt_41.data-00000-of-00001\n","ckpt_19.data-00000-of-00001  ckpt_41.index\n","ckpt_19.index\t\t     ckpt_42.data-00000-of-00001\n","ckpt_1.data-00000-of-00001   ckpt_42.index\n","ckpt_1.index\t\t     ckpt_43.data-00000-of-00001\n","ckpt_20.data-00000-of-00001  ckpt_43.index\n","ckpt_20.index\t\t     ckpt_44.data-00000-of-00001\n","ckpt_21.data-00000-of-00001  ckpt_44.index\n","ckpt_21.index\t\t     ckpt_45.data-00000-of-00001\n","ckpt_22.data-00000-of-00001  ckpt_45.index\n","ckpt_22.index\t\t     ckpt_46.data-00000-of-00001\n","ckpt_23.data-00000-of-00001  ckpt_46.index\n","ckpt_23.index\t\t     ckpt_47.data-00000-of-00001\n","ckpt_24.data-00000-of-00001  ckpt_47.index\n","ckpt_24.index\t\t     ckpt_48.data-00000-of-00001\n","ckpt_25.data-00000-of-00001  ckpt_48.index\n","ckpt_25.index\t\t     ckpt_49.data-00000-of-00001\n","ckpt_26.data-00000-of-00001  ckpt_49.index\n","ckpt_26.index\t\t     ckpt_4.data-00000-of-00001\n","ckpt_27.data-00000-of-00001  ckpt_4.index\n","ckpt_27.index\t\t     ckpt_50.data-00000-of-00001\n","ckpt_28.data-00000-of-00001  ckpt_50.index\n","ckpt_28.index\t\t     ckpt_5.data-00000-of-00001\n","ckpt_29.data-00000-of-00001  ckpt_5.index\n","ckpt_29.index\t\t     ckpt_6.data-00000-of-00001\n","ckpt_2.data-00000-of-00001   ckpt_6.index\n","ckpt_2.index\t\t     ckpt_7.data-00000-of-00001\n","ckpt_30.data-00000-of-00001  ckpt_7.index\n","ckpt_30.index\t\t     ckpt_8.data-00000-of-00001\n","ckpt_31.data-00000-of-00001  ckpt_8.index\n","ckpt_31.index\t\t     ckpt_9.data-00000-of-00001\n","ckpt_32.data-00000-of-00001  ckpt_9.index\n","ckpt_32.index\n"]}]},{"cell_type":"code","source":["# GENERACIÓN DE TEXTO CON EL MODELO\n","\n","tf.train.latest_checkpoint(checkpoint_dir)\n","\n","# Para mantenerlo simplle, se usará un tamaño de batch de 1.\n","# El modelo solo acepta un tamaño de batch fijo una vez construido, así que se\n","# necesita reconstruir manualmente el modelo con el método build() y restaurar sus\n","# pesos desde el Checkpoint\n","model=build_model(vocab_size, embedding_dim,\n","                  rnn_units,batch_size=1)\n","\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","\n","model.build(tf.TensorShape([1,None]))\n"],"metadata":{"id":"NgvarqN36dIj","executionInfo":{"status":"ok","timestamp":1692379634932,"user_tz":360,"elapsed":279,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["def generate_text(model,start_string):\n","\n","  num_generate=500 #Número de caracteres a predecir\n","  input_eval=[char2idx[s] for s in start_string] # start_string covierte la palabra\n","  # a su corresondiente representación numérica\n","  # Se preparan los tensores ncesarios\n","  input_eval = tf.expand_dims(input_eval,0)\n","  text_generated=[]\n","\n","  # Se usa la variabel temperatura para decir cuán observador en sus predicciones\n","  # queremos que sea nuestro modelo.\n","  # Con temperaturas altas (hasta 1) hay más creatividad pero con más errores.\n","  # Con temperaturas bajas habrá menos errores pero poca creatividad.\n","  temperature=0.5\n","\n","  model.reset_states()\n","  # Comienza el bucle para generar los caracteres que le hemos indicado\n","  for i in range(num_generate):\n","    predictions=model(input_eval)\n","    # Trabajamos con un batch tamaño 1, pero el modelo retorna el tensor del batch\n","    # con las dimensiones con que lo habíamos entrenado, hay que reducirlo\n","    predictions = tf.squeeze(predictions,0)\n","    # Se una distribución categórica para calcular el índice del carácter predicho\n","    predictions = predictions/temperature\n","    predicted_id=tf.random.categorical(predictions,\n","                                       num_samples=1)[-1,0].numpy()\n","    # Este carácter acabadod e predecir se usa como nuestra próxima entrada al modelo,\n","    # retroalimentando para que ahora tenga más contexto.\n","    input_eval = tf.expand_dims([predicted_id],0)\n","\n","    text_generated.append(idx2char[predicted_id])\n","\n","  return (start_string + ''.join(text_generated))"],"metadata":{"id":"otF14xmT-GZh","executionInfo":{"status":"ok","timestamp":1692379634932,"user_tz":360,"elapsed":4,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["# Probemos con una palabra que no conoce el modelo\n","print(generate_text(model, start_string= u\"domingo\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OMEdJ_e5-Gft","executionInfo":{"status":"ok","timestamp":1692379021244,"user_tz":360,"elapsed":4093,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"2bc2a963-2d82-4ad1-e23e-39978bf81a6f"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["domingo (ver Figura 6.8) con el que estos parámetros de ambas redes,\r\n","presentando algunas de las capas del modelo en cada epoch se implementado en el capítulo 13 antes de acabar es el carácter introductorio del libro entraremos en detalle en el hardware disponible en:\r\n","https://en.wikipedia.org/wiki/RGB [Consultado: 12/12/2019].\r\n","\r\n","\r\n","\r\n","51 Véase https://keras.io/layers/core/#dense [Consulta:\r\n","16/12/2019].\r\n","\r\n","\r\n","\r\n","99 Véase https://keras.io/callbacks/ [Consultado:\r\n","12/12/2019].\r\n","\r\n","\r\n","\r\n","51 Véase https://www.k\n"]}]},{"cell_type":"code","source":["# Probemos con una palabra que sí conoce\n","print(generate_text(model, start_string= u\"Ella\"))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"11Qa-vBd6dPf","executionInfo":{"status":"ok","timestamp":1692379638971,"user_tz":360,"elapsed":4041,"user":{"displayName":"Alex Mares","userId":"08856922341118214227"}},"outputId":"475a02e7-6792-4beb-f38c-e4846067d236"},"execution_count":33,"outputs":[{"output_type":"stream","name":"stdout","text":["Ellas fastras, y cuando el joven le hacía alguna observación, contestó un adilla por brazos yo como lo amargo! ¡Ese dio peo?\n","—¡Est Kués con ellas y sus fracasos.\n","Un mundo de emociones y sentimientos. Alguien decuento conciendo las cabezas de los\n","lwas murales en la cabeza.\n","—No, él no es eso. Es bueno oprendió es pero el muchachito de dinero para comportar la puerta.\n","—¿Quién la había llevado en seguida. Pero tendrías que es rediatar tú.\n","—Yo soy el colonel…\n","—¡No! ¡Es tungo nueve abrirtada. ¡De ninguna \n"]}]}]}